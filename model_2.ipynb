{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan\n",
    "1. Rewrite in keras - we already bucketing sequences\n",
    "2. Use an embedding layer to get drug code vectors.\n",
    "3. Get drug code tree thingy.\n",
    "4. Use rolling diagnosis to improve model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "#lets use the drug code\n",
    "import marshal, gzip\n",
    "pt_by_len = marshal.load(open('train_comprehensive_ptbylen.m', 'rb'))\n",
    "pred_by_len = marshal.load(open('pred_comprehensive_pts.m', 'rb'))\n",
    "\n",
    "def get_maxes():\n",
    "    hidden_max = [-1000.0] * 5\n",
    "    input_max = [-1000.0] * 12\n",
    "    for b in pt_by_len:\n",
    "        for hidden, inp, label in pt_by_len[b]:\n",
    "            for i, v in enumerate(hidden):\n",
    "                hidden_max[i] = max(hidden_max[i], v)\n",
    "            for inp_i in inp:\n",
    "                for i, v in enumerate(inp_i):\n",
    "                    input_max[i] = max(input_max[i], v)\n",
    "    print hidden_max\n",
    "    print input_max\n",
    "hidden_max = [1.0, 1.0, 1.0, 1.0, 2526]\n",
    "input_max = [0.997, 1.0, 4039, 6880.7, 1041874.5, 11682.85, 1, 6, 60258, 3182, 2869, 12] #must add 1!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245794 27453\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "def shuffle(length_arr):\n",
    "    train_pt_by_len = {}\n",
    "    test_pt_by_len = {}\n",
    "    for length in length_arr:\n",
    "        if len(length_arr[length]) >= 50:\n",
    "            train_pt_by_len[length], test_pt_by_len[length] = train_test_split(pt_by_len[length], test_size=0.1, random_state=42)\n",
    "    \n",
    "    return train_pt_by_len, test_pt_by_len\n",
    "\n",
    "train_pt_by_len, test_pt_by_len = shuffle(pt_by_len)\n",
    "bucketlengths = {}\n",
    "total = 0\n",
    "for b in train_pt_by_len:\n",
    "    bucketlengths[len(train_pt_by_len[b][0][1])] = len(train_pt_by_len[b])\n",
    "    total += len(train_pt_by_len[b])  \n",
    "\n",
    "def prepare_input(batch):\n",
    "    batch = zip(*batch)\n",
    "    \n",
    "    hidden = np.array(batch[0])\n",
    "    hidden = np.delete(hidden, (1,2,4),1) # something sex sex age code\n",
    "    hidden[:,1][hidden[:,1] == 1.0] = 0.5577 \n",
    "    \n",
    "    inp = np.array([l[1:] for l in batch[1]])\n",
    "    inp = np.delete(inp ,range(2,9), 2) # now with post code\n",
    "    \n",
    "    \n",
    "    labels = np.array(batch[2])\n",
    "    return hidden, inp, labels\n",
    "    \n",
    "\n",
    "def random_batch(batch_size=1):\n",
    "    chunk_len = np.random.choice(bucketlengths.keys(), 1, p=np.array(bucketlengths.values())/float(sum(bucketlengths.values())))[0]\n",
    "    bucket = np.array(train_pt_by_len[chunk_len])    \n",
    "    hidden, inp, labels = prepare_input(bucket[np.random.choice(bucket.shape[0], batch_size)])\n",
    "    \n",
    "    return hidden, inp, labels\n",
    "\n",
    "test_bucketlengths = {}\n",
    "test_total = 0\n",
    "for b in test_pt_by_len:\n",
    "    test_bucketlengths[len(test_pt_by_len[b][0][1])] = len(test_pt_by_len[b])\n",
    "    test_total += len(test_pt_by_len[b])\n",
    "\n",
    "def random_test_batch(batch_size=1):\n",
    "    chunk_len = np.random.choice(test_bucketlengths.keys(), 1, p=np.array(test_bucketlengths.values())/float(sum(test_bucketlengths.values())))[0]\n",
    "    bucket = np.array(test_pt_by_len[chunk_len])    \n",
    "    hidden, inp, labels = prepare_input(bucket[np.random.choice(bucket.shape[0], batch_size)])\n",
    "    \n",
    "    return hidden, inp, labels\n",
    "\n",
    "print total, test_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import os\n",
    "\n",
    "def torchify_batch(hidden, inp, target=None):\n",
    "    drugs = inp[:, :, -2]\n",
    "    dxs = inp[:, :, -1]\n",
    "    posts = inp[:,:,-3]\n",
    "    inp = inp[:, :, :-3]\n",
    "    hidden = np.repeat(hidden[:,np.newaxis, :], repeats=inp.shape[1], axis=1)\n",
    "    \n",
    "    inp = Variable(torch.from_numpy(inp), requires_grad=False)\n",
    "    posts = Variable(torch.from_numpy(posts), requires_grad=False).long()\n",
    "    drugs = Variable(torch.from_numpy(drugs), requires_grad=False).long()\n",
    "    dxs = Variable(torch.from_numpy(dxs), requires_grad=False).long()\n",
    "    hidden = Variable(torch.from_numpy(hidden), requires_grad=False)\n",
    "    if target is not None:\n",
    "        target = Variable(torch.from_numpy(target), requires_grad=False).long()\n",
    "    \n",
    "    return hidden, inp, posts, drugs, dxs, target\n",
    "\n",
    "def train(chkpoint, epochs, model, criterion, optimizer, train_losses, test_losses, test_aucs, cur_epoch=0, **kwargs):\n",
    "    total = 245794\n",
    "    for epoch in xrange(cur_epoch+1, epochs+1):\n",
    "        print('---Epoch {}---'.format(epoch))\n",
    "        num_cycles = total / 40\n",
    "        num_cycles /= 2\n",
    "        for cycle in tqdm_notebook(xrange(num_cycles)):\n",
    "            hidden, inp, target = random_batch(10)\n",
    "            hidden, inp, posts, drugs, dxs, target = torchify_batch(hidden, inp, target)\n",
    "            target.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            out = model(hidden.cuda(), inp.cuda(), posts.cuda(), drugs.cuda(), dxs.cuda())\n",
    "            loss = criterion(out, target.cuda())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        loss_var = loss.data.cpu().numpy()[0]\n",
    "\n",
    "        total_test_auc = 0\n",
    "        total_test_loss = 0\n",
    "\n",
    "        \n",
    "        batch_aucs = []\n",
    "        bootstrap = [validate(model) for _ in range(10)]\n",
    "        aucs = np.array([x[1] for x in bootstrap])\n",
    "        tests = np.array([x[0] for x in bootstrap])\n",
    "        all_test_loss, all_test_auc = validate_all(model)\n",
    "\n",
    "        #test_loss = total_test_loss/100.0\n",
    "        test_loss, test_loss_std = np.mean(tests), np.std(tests)\n",
    "        test_auc, test_auc_std = np.mean(aucs), np.std(aucs)\n",
    "\n",
    "        train_losses.append(loss_var)\n",
    "        test_losses.append(all_test_loss)\n",
    "        test_aucs.append(all_test_auc)\n",
    "        \n",
    "        if not os.path.exists(chkpoint[:-4]):\n",
    "            os.mkdir(chkpoint[:-4])\n",
    "\n",
    "        torch.save({\n",
    "                'cur_epoch': epoch,\n",
    "                'train_losses': train_losses,\n",
    "                'test_losses': test_losses,\n",
    "                'model': model,\n",
    "                'criterion': criterion,\n",
    "                'optimizer': optimizer,\n",
    "                'test_aucs': test_aucs,\n",
    "            }, '{}/epoch-{}-{}.tar'.format(chkpoint[:-4], epoch, int(all_test_auc * 1000)))\n",
    "        \n",
    "        \n",
    "\n",
    "        print('Train Loss: {}'.format(loss_var)) # pass arguments to affect saving / resume behaviour\n",
    "        print('Test Loss: {} Std: {}'.format(test_loss, test_loss_std))\n",
    "        print('Test AUC: {} Std: {}'.format(test_auc, test_auc_std))\n",
    "        print('All Test Loss: {} AUC: {}'.format(all_test_loss, all_test_auc))\n",
    "        \n",
    "\n",
    "def validate_all(model):\n",
    "    all_true = np.zeros((test_total, 2))\n",
    "    all_pred = np.zeros((test_total, 2))\n",
    "    total_test_loss = 0\n",
    "    i = 0\n",
    "    for b in test_pt_by_len:\n",
    "        hidden, inp, target = prepare_input(np.array(test_pt_by_len[b]))\n",
    "        target2 = target[:]\n",
    "        hidden, inp, posts, drugs, dxs, target = torchify_batch(hidden, inp, target)\n",
    "        out = model(hidden.cuda(), inp.cuda(), posts.cuda(), drugs.cuda(), dxs.cuda())\n",
    "\n",
    "        target.cuda()\n",
    "\n",
    "        loss = criterion(out, target.cuda())\n",
    "        out_np = out.data.cpu().numpy()\n",
    "        for j in xrange(target2.shape[0]):\n",
    "            all_true[i, int(target2[j])] = 1\n",
    "            all_pred[i] = out_np[j]\n",
    "            i += 1\n",
    "        total_test_loss += loss.data.cpu().numpy()[0]\n",
    "    test_loss = total_test_loss/288\n",
    "    test_auc = roc_auc_score(all_true, all_pred)\n",
    "    return test_loss, test_auc\n",
    "\n",
    "def validate(model):\n",
    "    total_test_loss = 0\n",
    "    all_true = np.zeros((4000, 2))\n",
    "    all_pred = np.zeros((4000, 2))\n",
    "    for i in xrange(100):\n",
    "        hidden, inp, target = random_test_batch(40)\n",
    "        target2 = target[:]\n",
    "        hidden, inp, posts, drugs, dxs, target = torchify_batch(hidden, inp, target)\n",
    "        out = model(hidden.cuda(), inp.cuda(), posts.cuda(), drugs.cuda(), dxs.cuda())\n",
    "\n",
    "        target.cuda()\n",
    "\n",
    "        loss = criterion(out, target.cuda())\n",
    "        out_np = out.data.cpu().numpy()\n",
    "        for j in xrange(40):\n",
    "            all_true[i*40 + j, int(target2[j])] = 1\n",
    "            all_pred[i*40+j] = out_np[j]\n",
    "        total_test_loss += loss.data.cpu().numpy()[0]\n",
    "\n",
    "    test_loss = total_test_loss/100.0\n",
    "    test_auc = roc_auc_score(all_true, all_pred)\n",
    "    return test_loss, test_auc\n",
    "    \n",
    "\n",
    "def generate_predictions_csv(model, filename):\n",
    "    predictions = []\n",
    "    for b in tqdm_notebook(pred_by_len):\n",
    "        hidden, inp, pt_id = prepare_input(pred_by_len[b])\n",
    "        hidden, inp, posts, drugs, dxs, _ = torchify_batch(hidden, inp)\n",
    "        out = model(hidden.cuda(), inp.cuda(), posts.cuda(), drugs.cuda(), dxs.cuda()).data.cpu().numpy()\n",
    "        predictions.extend(zip(pt_id, out[:,1]))\n",
    "\n",
    "    predictions.sort()\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write('Patient_ID,Diabetes\\n')\n",
    "        for a, b in predictions:\n",
    "            f.write('{},{}\\n'.format(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Epoch 1---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f67e58e30b304ce58d970f18f884d0a3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0689777711046\n",
      "Test Loss: 0.139143354553 Std: 0.0100965572264\n",
      "Test AUC: 0.963551502081 Std: 0.00411085046495\n",
      "All Test Loss: 0.167774187775 AUC: 0.961062705566\n",
      "---Epoch 2---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6de04a746cd40438eb8e575566eaa21"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0788653737222\n",
      "Test Loss: 0.135229578957 Std: 0.0114813951585\n",
      "Test AUC: 0.959760324745 Std: 0.00360535543833\n",
      "All Test Loss: 0.15842264203 AUC: 0.962341806405\n",
      "---Epoch 3---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9725f32c27e4a0b8747bcb985c39bef"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.232331981637\n",
      "Test Loss: 0.132471837236 Std: 0.0123586937796\n",
      "Test AUC: 0.963591195841 Std: 0.00379349473943\n",
      "All Test Loss: 0.147105437304 AUC: 0.964149151214\n",
      "---Epoch 4---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "effc175fa3e4402285f2277e28e4b1b6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.307106588809\n",
      "Test Loss: 0.132943574897 Std: 0.00917150965587\n",
      "Test AUC: 0.962268985592 Std: 0.00271662173597\n",
      "All Test Loss: 0.150821224703 AUC: 0.962897529925\n",
      "---Epoch 5---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a7a0a2474e14481949a8a8e17a9c097"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0131785634836\n",
      "Test Loss: 0.137195608801 Std: 0.0168099488957\n",
      "Test AUC: 0.961451786595 Std: 0.00570088104755\n",
      "All Test Loss: 0.150031045913 AUC: 0.963711709989\n",
      "---Epoch 6---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10d028a4cf85487dba9e4ef102334e78"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.356706176602\n",
      "Test Loss: 0.130280184755 Std: 0.0107837494641\n",
      "Test AUC: 0.96265178552 Std: 0.00234362607094\n",
      "All Test Loss: 0.145402238672 AUC: 0.962972702972\n",
      "---Epoch 7---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37ef04707d0744b7b2e7f386142466f3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.174981439217\n",
      "Test Loss: 0.131265032437 Std: 0.0108829549045\n",
      "Test AUC: 0.965891805225 Std: 0.00457307027515\n",
      "All Test Loss: 0.144663551556 AUC: 0.964215077916\n",
      "---Epoch 8---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8890782fdb0d4365857486de8cedc96b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.042237726291\n",
      "Test Loss: 0.132956330639 Std: 0.0103623905177\n",
      "Test AUC: 0.963261224938 Std: 0.00657248280708\n",
      "All Test Loss: 0.14756344431 AUC: 0.964463258821\n",
      "---Epoch 9---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0de7bec099b140358dff64e33f489b40"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.400223799847\n",
      "Test Loss: 0.136650925481 Std: 0.00954361592616\n",
      "Test AUC: 0.964088176401 Std: 0.00409950821714\n",
      "All Test Loss: 0.154372589353 AUC: 0.965001423799\n",
      "---Epoch 10---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f90fc951d9647ea94540cdde4a4102a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0268753791597\n",
      "Test Loss: 0.129271417738 Std: 0.00926633843804\n",
      "Test AUC: 0.966423301161 Std: 0.00362448466319\n",
      "All Test Loss: 0.151078762804 AUC: 0.965391041784\n",
      "---Epoch 11---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dea6b572d054b9a8d6ca5fed8297307"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0133227636567\n",
      "Test Loss: 0.127533586732 Std: 0.00964351603864\n",
      "Test AUC: 0.965976855719 Std: 0.00788742843195\n",
      "All Test Loss: 0.143984634414 AUC: 0.964943281672\n",
      "---Epoch 12---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0319498b21414202baf03e9ac82b4bba"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0483414125284\n",
      "Test Loss: 0.131551325353 Std: 0.00990921531043\n",
      "Test AUC: 0.964185270673 Std: 0.00507626442437\n",
      "All Test Loss: 0.148636198295 AUC: 0.964044959001\n",
      "---Epoch 13---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f722b99875b4061b22e3e79bd943ff8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0160181601099\n",
      "Test Loss: 0.123382012344 Std: 0.00607747293897\n",
      "Test AUC: 0.96762575206 Std: 0.00541198568466\n",
      "All Test Loss: 0.143046793066 AUC: 0.964936560989\n",
      "---Epoch 14---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad7463b0beb945bfbd66871be9820569"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0208986357823\n",
      "Test Loss: 0.132625480774 Std: 0.00601775807189\n",
      "Test AUC: 0.963950913665 Std: 0.00285713297838\n",
      "All Test Loss: 0.145064098306 AUC: 0.964623621068\n",
      "---Epoch 15---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c5bfc184bd140b28e96bd2cc010eb29"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.05114747609\n",
      "Test Loss: 0.136046804668 Std: 0.00477787378534\n",
      "Test AUC: 0.963610202317 Std: 0.00409010133339\n",
      "All Test Loss: 0.149416251212 AUC: 0.96356913982\n",
      "---Epoch 16---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c157da50f2d4d058b950866233d501b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0315445257035\n",
      "Test Loss: 0.134983104573 Std: 0.00919887224629\n",
      "Test AUC: 0.963781012353 Std: 0.0054128119344\n",
      "All Test Loss: 0.141361447271 AUC: 0.965269291029\n",
      "---Epoch 17---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b16da3224cc4ffdb6be26e01d9d3b2d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0606381414075\n",
      "Test Loss: 0.13467658848 Std: 0.0100782273236\n",
      "Test AUC: 0.963228458696 Std: 0.00464396728626\n",
      "All Test Loss: 0.144167746754 AUC: 0.965037976704\n",
      "---Epoch 18---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2752a47f0e8549c3897485ec2f92e515"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0751298662889\n",
      "Test Loss: 0.129416860061 Std: 0.00859767846162\n",
      "Test AUC: 0.964673303566 Std: 0.00542460307611\n",
      "All Test Loss: 0.142338762399 AUC: 0.964706258658\n",
      "---Epoch 19---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13b9d6a18c99430ebac8e3e4ce834d82"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0444802537421\n",
      "Test Loss: 0.128693611422 Std: 0.00794881198575\n",
      "Test AUC: 0.963944298396 Std: 0.00510195796603\n",
      "All Test Loss: 0.143850606239 AUC: 0.965444755353\n",
      "---Epoch 20---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b6cee702667486d8ccc7d5fdff76385"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0413771589847\n",
      "Test Loss: 0.129207157617 Std: 0.00732143545413\n",
      "Test AUC: 0.962734447076 Std: 0.00437819433825\n",
      "All Test Loss: 0.141247798464 AUC: 0.964632780919\n",
      "---Epoch 21---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "813da4ca9d3b4752a572746d59499fe9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.150077609837\n",
      "Test Loss: 0.135329277264 Std: 0.00795085012545\n",
      "Test AUC: 0.965435586172 Std: 0.0042216540064\n",
      "All Test Loss: 0.143989118655 AUC: 0.965006362679\n",
      "---Epoch 22---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fb24c1ff32247c5bd7de7dc2a33b03d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0210437961294\n",
      "Test Loss: 0.138196394426 Std: 0.0103596805236\n",
      "Test AUC: 0.961042200398 Std: 0.00761508454872\n",
      "All Test Loss: 0.150253877972 AUC: 0.964474987581\n",
      "---Epoch 23---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef7052cd33224a8e9ca43783429a7fc1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0181376788076\n",
      "Test Loss: 0.12976432642 Std: 0.00905578030446\n",
      "Test AUC: 0.96436347431 Std: 0.00571773067006\n",
      "All Test Loss: 0.140568345862 AUC: 0.964320368619\n",
      "---Epoch 24---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7187fb5dd7084f2782f8be339e2357ac"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0345421580749\n",
      "Test Loss: 0.124515212076 Std: 0.00704158441517\n",
      "Test AUC: 0.965283942488 Std: 0.00329179655501\n",
      "All Test Loss: 0.146369029362 AUC: 0.964303951815\n",
      "---Epoch 25---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "857940e5d69949cbbc6f0596fb665e11"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.013884925233\n",
      "Test Loss: 0.126668925973 Std: 0.00461887766361\n",
      "Test AUC: 0.96483580637 Std: 0.00534395017435\n",
      "All Test Loss: 0.143300143566 AUC: 0.963376826216\n",
      "---Epoch 26---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11ab9f0c9f0d4bdeb2035e47957750aa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0241809574303\n",
      "Test Loss: 0.12691577802 Std: 0.00952415324344\n",
      "Test AUC: 0.964207879603 Std: 0.00586829390225\n",
      "All Test Loss: 0.139356911616 AUC: 0.964905898412\n",
      "---Epoch 27---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c335b4b4755048fd93ab4d49c12b5a95"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0340970827636\n",
      "Test Loss: 0.13356355293 Std: 0.0051496882335\n",
      "Test AUC: 0.963169394512 Std: 0.00353028433383\n",
      "All Test Loss: 0.149844353122 AUC: 0.965310886609\n",
      "---Epoch 28---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e628e61a6ffa450382deec02cd622ce6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.456191513538\n",
      "Test Loss: 0.130933003644 Std: 0.00976572167229\n",
      "Test AUC: 0.964250145485 Std: 0.00439665144654\n",
      "All Test Loss: 0.145077831062 AUC: 0.964937261601\n",
      "---Epoch 29---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa3c0a8923ac4c71b4dae22368514c26"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0209050584002\n",
      "Test Loss: 0.133607565553 Std: 0.0103775912104\n",
      "Test AUC: 0.960822636136 Std: 0.00573693351248\n",
      "All Test Loss: 0.141965483561 AUC: 0.964891540196\n",
      "---Epoch 30---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52f21a0de4004636b4c86e1d7c9745cf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.449723636691\n",
      "Test Loss: 0.132004746305 Std: 0.0106065715671\n",
      "Test AUC: 0.962522831656 Std: 0.00652181456651\n",
      "All Test Loss: 0.142600326606 AUC: 0.964612471827\n"
     ]
    }
   ],
   "source": [
    "class Model1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model1, self).__init__()\n",
    "        self.post_embedding = nn.Embedding(3182, 2)\n",
    "        self.drug_embedding = nn.Embedding(2870, 20)#changed from 30\n",
    "        #self.inp_embedding = nn.Embedding(2, 10)\n",
    "        self.dx_embedding = nn.Embedding(12, 7) #changed from 5 to 7\n",
    "        self.gru1 = nn.GRU(33, 64, 4, batch_first=True)\n",
    "        self.dense1 = nn.Linear(64, 2)\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "    \n",
    "    def forward(self, hidden, inp, posts, drugs, dxs):\n",
    "        posts_e = self.post_embedding(posts)\n",
    "        drugs_e = self.drug_embedding(drugs)\n",
    "        dxs_e = self.dx_embedding(dxs)\n",
    "        #inp_e = self.inp_embedding(inp)\n",
    "        final_input = torch.cat((hidden, inp, posts_e, drugs_e, dxs_e),dim=2)\n",
    "    \n",
    "        h_1 = Variable(torch.zeros(4,inp.size(0), 64).double(), requires_grad=False).cuda()\n",
    "        output, h_2 = self.gru1(final_input, h_1)\n",
    "\n",
    "        x = self.dense1(h_2[-1])\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "#np.random.seed(42) # new seed\n",
    "#torch.manual_seed(42)\n",
    "\n",
    "model = Model1()\n",
    "model.double()\n",
    "model.cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "test_aucs = []\n",
    "\n",
    "train(chkpoint='model11_post9_4_64_lr_001.tar', \n",
    "      epochs=30, \n",
    "      model=model, \n",
    "      optimizer=optimizer, \n",
    "      criterion=criterion, \n",
    "      test_losses=test_losses,\n",
    "     train_losses=train_losses,\n",
    "     test_aucs=test_aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = torch.load('model10_post9_3_64_lr_001/epoch-2-963.tar')\n",
    "#data_dict['optimizer'] = torch.optim.Adam(model.parameters(), lr=0.0003)\n",
    "#data_dict['optimizer'] = torch.optim.SGD(model.parameters(), lr=0.001, momentum=1.3, nesterov=True)\n",
    "train(chkpoint='model10_post9_3_64_lr_001.tar', epochs=30, **data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.958957016353 0.00762216388464\n",
      "CPU times: user 19.3 s, sys: 565 ms, total: 19.8 s\n",
      "Wall time: 19.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "aucs = np.array([validate(model)[1] for x in range(10)])\n",
    "print np.mean(aucs), np.std(aucs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62930d9b0c4b461094280b1b24b577bc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_dict = torch.load('model11_post9_4_64_lr_001/epoch-19-965.tar')\n",
    "generate_predictions_csv(data_dict['model'], 'out-log-softmax-965.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring where the mistakes are coming from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_true = np.zeros((test_total))\n",
    "all_pred = np.zeros((test_total))\n",
    "\n",
    "bad_answers = []\n",
    "\n",
    "total_test_loss = 0\n",
    "i = 0\n",
    "for b in test_pt_by_len:\n",
    "    hidden, inp, target = prepare_input(np.array(test_pt_by_len[b]))\n",
    "    target2 = target[:]\n",
    "    hidden2 = hidden[:]\n",
    "    inp2 = inp[:]\n",
    "    hidden, inp, posts, drugs, dxs, target = torchify_batch(hidden, inp, target)\n",
    "    out = model(hidden.cuda(), inp.cuda(), posts.cuda(), drugs.cuda(), dxs.cuda())\n",
    "\n",
    "    target.cuda()\n",
    "\n",
    "    loss = criterion(out, target.cuda())\n",
    "    out_np = out.data.cpu().numpy()\n",
    "    for j in xrange(target2.shape[0]):\n",
    "        all_true[i] = int(target2[j])\n",
    "        all_pred[i] = out_np[j][1]\n",
    "        if abs(all_true[i] - all_pred[i]) > 0.99:\n",
    "            bad_answers.append((target2[j], hidden2[j], inp2[j]))\n",
    "        i += 1\n",
    "    total_test_loss += loss.data.cpu().numpy()[0]\n",
    "test_loss = total_test_loss/288\n",
    "test_auc = roc_auc_score(all_true, all_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "802\n"
     ]
    }
   ],
   "source": [
    "uros = 0\n",
    "for target, hidden, transaction in bad_answers:\n",
    "    uros += (np.sum(transaction[:, 4] == 11) > 0)\n",
    "print uros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7180.51899610243"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "802.0 / test_total * total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error = all_true - all_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc4b7289910>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc4b6efab50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(all_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc4b6e94c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc4b6b3bed0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAAD8CAYAAAC4uSVNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc4b6fbbf90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.distplot(error)\n",
    "plt.show()\n",
    "sns.distplot(np.abs(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1354\n",
      "861\n",
      "0.0313626926019\n"
     ]
    }
   ],
   "source": [
    "print np.sum(np.abs(error) > 0.01) 1354\n",
    "print np.sum(np.abs(error) > 0.99) 864\n",
    "print 861.0/test_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.abs(error) > 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27453"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6753d0390b74d0b83fd08014f1cf555"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generate_predictions_csv(model, 'out1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Epoch 8---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a46f5c5933874bc7b1af983bb6de46b4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train('model_post1.1_3_32_lr_001.tar', epochs=10, **torch.load('model_post1_3_32_lr_001.tar'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': CrossEntropyLoss (\n",
       " ), 'cur_epoch': 4, 'model': Model1 (\n",
       "   (drug_embedding): Embedding(2870, 30)\n",
       "   (dx_embedding): Embedding(12, 5)\n",
       "   (gru1): GRU(39, 32, num_layers=3, batch_first=True)\n",
       "   (dense1): Linear (32 -> 2)\n",
       "   (softmax): Softmax ()\n",
       " ), 'optimizer': <torch.optim.adam.Adam at 0x7f23016a2350>, 'test_aucs': [0.9497745120551091,\n",
       "  0.95737772101378837,\n",
       "  0.96352282510260245,\n",
       "  0.97322535701846047], 'test_losses': [0.35393751389666983,\n",
       "  0.35761409787089349,\n",
       "  0.35281944691292533,\n",
       "  0.34829183176775053], 'train_losses': [0.37126914617345386,\n",
       "  0.33828777079089706,\n",
       "  0.33836713117440947,\n",
       "  0.39558140579214862]}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load('model_3_32_lr_001.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47bc7c8a91274a079942b00ee753648a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.35821641802842302, 0.94314307203172887)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def validate_all(model):\n",
    "    all_true = np.zeros((test_total, 2))\n",
    "    all_pred = np.zeros((test_total, 2))\n",
    "    total_test_loss = 0\n",
    "    i = 0\n",
    "    for b in tqdm_notebook(test_pt_by_len):\n",
    "        hidden, inp, target = prepare_input(np.array(test_pt_by_len[b]))\n",
    "        target2 = target[:]\n",
    "        hidden, inp, posts, drugs, dxs, target = torchify_batch(hidden, inp, target)\n",
    "        out = model(hidden.cuda(), inp.cuda(), posts.cuda(), drugs.cuda(), dxs.cuda())\n",
    "\n",
    "        target.cuda()\n",
    "\n",
    "        loss = criterion(out, target.cuda())\n",
    "        out_np = out.data.cpu().numpy()\n",
    "        for j in xrange(target2.shape[0]):\n",
    "            all_true[i, int(target2[j])] = 1\n",
    "            all_pred[i] = out_np[j]\n",
    "            i += 1\n",
    "        total_test_loss += loss.data.cpu().numpy()[0]\n",
    "    test_loss = total_test_loss/288\n",
    "    test_auc = roc_auc_score(all_true, all_pred)\n",
    "    return test_loss, test_auc\n",
    "\n",
    "validate_all(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27453"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
