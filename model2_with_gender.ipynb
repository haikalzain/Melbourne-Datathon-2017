{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan\n",
    "1. Rewrite in keras - we already bucketing sequences\n",
    "2. Use an embedding layer to get drug code vectors.\n",
    "3. Get drug code tree thingy.\n",
    "4. Use rolling diagnosis to improve model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "#lets use the drug code\n",
    "import marshal, gzip\n",
    "pt_by_len = marshal.load(open('train_comprehensive_ptbylen.m', 'rb'))\n",
    "pred_by_len = marshal.load(open('pred_comprehensive_pts.m', 'rb'))\n",
    "\n",
    "def get_maxes():\n",
    "    hidden_max = [-1000.0] * 5\n",
    "    input_max = [-1000.0] * 12\n",
    "    for b in pt_by_len:\n",
    "        for hidden, inp, label in pt_by_len[b]:\n",
    "            for i, v in enumerate(hidden):\n",
    "                hidden_max[i] = max(hidden_max[i], v)\n",
    "            for inp_i in inp:\n",
    "                for i, v in enumerate(inp_i):\n",
    "                    input_max[i] = max(input_max[i], v)\n",
    "    print hidden_max\n",
    "    print input_max\n",
    "hidden_max = [1.0, 1.0, 1.0, 1.0, 2526]\n",
    "input_max = [0.997, 1.0, 4039, 6880.7, 1041874.5, 11682.85, 1, 6, 60258, 3182, 2869, 12] #must add 1!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245794 27453\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "def shuffle(length_arr):\n",
    "    train_pt_by_len = {}\n",
    "    test_pt_by_len = {}\n",
    "    for length in length_arr:\n",
    "        if len(length_arr[length]) >= 50:\n",
    "            train_pt_by_len[length], test_pt_by_len[length] = train_test_split(pt_by_len[length], test_size=0.1, random_state=42)\n",
    "    \n",
    "    return train_pt_by_len, test_pt_by_len\n",
    "\n",
    "train_pt_by_len, test_pt_by_len = shuffle(pt_by_len)\n",
    "bucketlengths = {}\n",
    "total = 0\n",
    "for b in train_pt_by_len:\n",
    "    bucketlengths[len(train_pt_by_len[b][0][1])] = len(train_pt_by_len[b])\n",
    "    total += len(train_pt_by_len[b])  \n",
    "\n",
    "def prepare_input(batch):\n",
    "    batch = zip(*batch)\n",
    "    \n",
    "    hidden = np.array(batch[0])\n",
    "    hidden = np.delete(hidden, (4,),1) # something sex sex age code\n",
    "    hidden[:,3][hidden[:,3] == 1.0] = 0.5577 \n",
    "    \n",
    "    inp = np.array([l[1:] for l in batch[1]])\n",
    "    inp = np.delete(inp ,range(2,9), 2) # now with post code\n",
    "    \n",
    "    \n",
    "    labels = np.array(batch[2])\n",
    "    return hidden, inp, labels\n",
    "    \n",
    "\n",
    "def random_batch(batch_size=1):\n",
    "    chunk_len = np.random.choice(bucketlengths.keys(), 1, p=np.array(bucketlengths.values())/float(sum(bucketlengths.values())))[0]\n",
    "    bucket = np.array(train_pt_by_len[chunk_len])    \n",
    "    hidden, inp, labels = prepare_input(bucket[np.random.choice(bucket.shape[0], batch_size)])\n",
    "    \n",
    "    return hidden, inp, labels\n",
    "\n",
    "test_bucketlengths = {}\n",
    "test_total = 0\n",
    "for b in test_pt_by_len:\n",
    "    test_bucketlengths[len(test_pt_by_len[b][0][1])] = len(test_pt_by_len[b])\n",
    "    test_total += len(test_pt_by_len[b])\n",
    "\n",
    "def random_test_batch(batch_size=1):\n",
    "    chunk_len = np.random.choice(test_bucketlengths.keys(), 1, p=np.array(test_bucketlengths.values())/float(sum(test_bucketlengths.values())))[0]\n",
    "    bucket = np.array(test_pt_by_len[chunk_len])    \n",
    "    hidden, inp, labels = prepare_input(bucket[np.random.choice(bucket.shape[0], batch_size)])\n",
    "    \n",
    "    return hidden, inp, labels\n",
    "\n",
    "print total, test_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import os\n",
    "\n",
    "def torchify_batch(hidden, inp, target=None):\n",
    "    drugs = inp[:, :, -2]\n",
    "    dxs = inp[:, :, -1]\n",
    "    posts = inp[:,:,-3]\n",
    "    inp = inp[:, :, :-3]\n",
    "    hidden = np.repeat(hidden[:,np.newaxis, :], repeats=inp.shape[1], axis=1)\n",
    "    \n",
    "    inp = Variable(torch.from_numpy(inp), requires_grad=False)\n",
    "    posts = Variable(torch.from_numpy(posts), requires_grad=False).long()\n",
    "    drugs = Variable(torch.from_numpy(drugs), requires_grad=False).long()\n",
    "    dxs = Variable(torch.from_numpy(dxs), requires_grad=False).long()\n",
    "    hidden = Variable(torch.from_numpy(hidden), requires_grad=False)\n",
    "    if target is not None:\n",
    "        target = Variable(torch.from_numpy(target), requires_grad=False).long()\n",
    "    \n",
    "    return hidden, inp, posts, drugs, dxs, target\n",
    "\n",
    "def train(chkpoint, epochs, model, criterion, optimizer, train_losses, test_losses, test_aucs, cur_epoch=0, **kwargs):\n",
    "    total = 245794\n",
    "    for epoch in xrange(cur_epoch+1, epochs+1):\n",
    "        print('---Epoch {}---'.format(epoch))\n",
    "        num_cycles = total / 40\n",
    "        num_cycles /= 2\n",
    "        for cycle in tqdm_notebook(xrange(num_cycles)):\n",
    "            hidden, inp, target = random_batch(10)\n",
    "            hidden, inp, posts, drugs, dxs, target = torchify_batch(hidden, inp, target)\n",
    "            target.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            out = model(hidden.cuda(), inp.cuda(), posts.cuda(), drugs.cuda(), dxs.cuda())\n",
    "            loss = criterion(out, target.cuda())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        loss_var = loss.data.cpu().numpy()[0]\n",
    "\n",
    "        total_test_auc = 0\n",
    "        total_test_loss = 0\n",
    "\n",
    "        \n",
    "        batch_aucs = []\n",
    "        #bootstrap = [validate(model) for _ in range(10)]\n",
    "        #aucs = np.array([x[1] for x in bootstrap])\n",
    "        #tests = np.array([x[0] for x in bootstrap])\n",
    "        all_test_loss, all_test_auc = validate_all(model)\n",
    "\n",
    "        #test_loss = total_test_loss/100.0\n",
    "        #test_loss, test_loss_std = np.mean(tests), np.std(tests)\n",
    "        #test_auc, test_auc_std = np.mean(aucs), np.std(aucs)\n",
    "\n",
    "        train_losses.append(loss_var)\n",
    "        test_losses.append(all_test_loss)\n",
    "        test_aucs.append(all_test_auc)\n",
    "        \n",
    "        if not os.path.exists(chkpoint[:-4]):\n",
    "            os.mkdir(chkpoint[:-4])\n",
    "\n",
    "        torch.save({\n",
    "                'cur_epoch': epoch,\n",
    "                'train_losses': train_losses,\n",
    "                'test_losses': test_losses,\n",
    "                'model': model,\n",
    "                'criterion': criterion,\n",
    "                'optimizer': optimizer,\n",
    "                'test_aucs': test_aucs,\n",
    "            }, '{}/epoch-{}-{}.tar'.format(chkpoint[:-4], epoch, int(all_test_auc * 1000)))\n",
    "        \n",
    "        \n",
    "\n",
    "        print('Train Loss: {}'.format(loss_var)) # pass arguments to affect saving / resume behaviour\n",
    "        #print('Test Loss: {} Std: {}'.format(test_loss, test_loss_std))\n",
    "        #print('Test AUC: {} Std: {}'.format(test_auc, test_auc_std))\n",
    "        print('All Test Loss: {} AUC: {}'.format(all_test_loss, all_test_auc))\n",
    "        \n",
    "\n",
    "def validate_all(model):\n",
    "    all_true = np.zeros((test_total, 2))\n",
    "    all_pred = np.zeros((test_total, 2))\n",
    "    total_test_loss = 0\n",
    "    i = 0\n",
    "    for b in test_pt_by_len:\n",
    "        hidden, inp, target = prepare_input(np.array(test_pt_by_len[b]))\n",
    "        target2 = target[:]\n",
    "        hidden, inp, posts, drugs, dxs, target = torchify_batch(hidden, inp, target)\n",
    "        out = model(hidden.cuda(), inp.cuda(), posts.cuda(), drugs.cuda(), dxs.cuda())\n",
    "\n",
    "        target.cuda()\n",
    "\n",
    "        loss = criterion(out, target.cuda())\n",
    "        out_np = out.data.cpu().numpy()\n",
    "        for j in xrange(target2.shape[0]):\n",
    "            all_true[i, int(target2[j])] = 1\n",
    "            all_pred[i] = out_np[j]\n",
    "            i += 1\n",
    "        total_test_loss += loss.data.cpu().numpy()[0]\n",
    "    test_loss = total_test_loss/288\n",
    "    test_auc = roc_auc_score(all_true, all_pred)\n",
    "    return test_loss, test_auc\n",
    "\n",
    "def validate(model):\n",
    "    total_test_loss = 0\n",
    "    all_true = np.zeros((4000, 2))\n",
    "    all_pred = np.zeros((4000, 2))\n",
    "    for i in xrange(100):\n",
    "        hidden, inp, target = random_test_batch(40)\n",
    "        target2 = target[:]\n",
    "        hidden, inp, posts, drugs, dxs, target = torchify_batch(hidden, inp, target)\n",
    "        out = model(hidden.cuda(), inp.cuda(), posts.cuda(), drugs.cuda(), dxs.cuda())\n",
    "\n",
    "        target.cuda()\n",
    "\n",
    "        loss = criterion(out, target.cuda())\n",
    "        out_np = out.data.cpu().numpy()\n",
    "        for j in xrange(40):\n",
    "            all_true[i*40 + j, int(target2[j])] = 1\n",
    "            all_pred[i*40+j] = out_np[j]\n",
    "        total_test_loss += loss.data.cpu().numpy()[0]\n",
    "\n",
    "    test_loss = total_test_loss/100.0\n",
    "    test_auc = roc_auc_score(all_true, all_pred)\n",
    "    return test_loss, test_auc\n",
    "    \n",
    "\n",
    "def generate_predictions_csv(model, filename):\n",
    "    predictions = []\n",
    "    for b in tqdm_notebook(pred_by_len):\n",
    "        hidden, inp, pt_id = prepare_input(pred_by_len[b])\n",
    "        hidden, inp, posts, drugs, dxs, _ = torchify_batch(hidden, inp)\n",
    "        out = model(hidden.cuda(), inp.cuda(), posts.cuda(), drugs.cuda(), dxs.cuda()).data.cpu().numpy()\n",
    "        predictions.extend(zip(pt_id, out[:,1]))\n",
    "\n",
    "    predictions.sort()\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write('Patient_ID,Diabetes\\n')\n",
    "        for a, b in predictions:\n",
    "            f.write('{},{}\\n'.format(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model1, self).__init__()\n",
    "        self.post_embedding = nn.Embedding(3182, 2)\n",
    "        self.drug_embedding = nn.Embedding(2870, 20)#changed from 30\n",
    "        #self.inp_embedding = nn.Embedding(2, 10)\n",
    "        self.dx_embedding = nn.Embedding(12, 7) #changed from 5 to 7\n",
    "        self.gru1 = nn.GRU(35, 96, 4, batch_first=True,dropout=0.2)\n",
    "        self.dense1 = nn.Linear(96, 2)\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "    \n",
    "    def forward(self, hidden, inp, posts, drugs, dxs):\n",
    "        posts_e = self.post_embedding(posts)\n",
    "        drugs_e = self.drug_embedding(drugs)\n",
    "        dxs_e = self.dx_embedding(dxs)\n",
    "        #inp_e = self.inp_embedding(inp)\n",
    "        final_input = torch.cat((hidden, inp, posts_e, drugs_e, dxs_e),dim=2)\n",
    "    \n",
    "        h_1 = Variable(torch.zeros(4,inp.size(0), 96).double(), requires_grad=False).cuda()\n",
    "        output, h_2 = self.gru1(final_input, h_1)\n",
    "\n",
    "        x = self.dense1(h_2[-1])\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Epoch 1---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5b555e9c1464a048be8bdfbded5eef0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0254803099756\n",
      "All Test Loss: 0.19576329119 AUC: 0.951423801387\n",
      "---Epoch 2---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7d613ff0dab4414ba374b97aa149465"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0245366807296\n",
      "All Test Loss: 0.161425788486 AUC: 0.958323547113\n",
      "---Epoch 3---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a55cbd81a2904ae582f7883037a63dbc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.176811447575\n",
      "All Test Loss: 0.154061450668 AUC: 0.96129459076\n",
      "---Epoch 4---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba534026e3534f8b84c54bbcc0475b4b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.139227078605\n",
      "All Test Loss: 0.152362023483 AUC: 0.961509349889\n",
      "---Epoch 5---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60521797e5c54bc4b1588b7e726d7d55"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.411345461107\n",
      "All Test Loss: 0.155256215859 AUC: 0.962709229702\n",
      "---Epoch 6---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9790cb79e2414eea9ad60a12a4a251e0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.171678976367\n",
      "All Test Loss: 0.148451783452 AUC: 0.963225926552\n",
      "---Epoch 7---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6155d32eaaa741549a4bf3b5a7a9c9cd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0334983584196\n",
      "All Test Loss: 0.153010733751 AUC: 0.964304548633\n",
      "---Epoch 8---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "073f78bbf34f48ceb63cf9b8749e2b6f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.452200215326\n",
      "All Test Loss: 0.148272181206 AUC: 0.962920304132\n",
      "---Epoch 9---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1fe2d81a92441be8ecb9c2ef8a80d69"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.336839195964\n",
      "All Test Loss: 0.145948184742 AUC: 0.963634841634\n",
      "---Epoch 10---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b67c5e50a764454a918169a42c8a7e03"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.111368793041\n",
      "All Test Loss: 0.145168137777 AUC: 0.964518460108\n",
      "---Epoch 11---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fac243e8d4a64b1084abe862b43a1a5f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0654398232088\n",
      "All Test Loss: 0.144487192772 AUC: 0.964404580423\n",
      "---Epoch 12---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8183bcf51c064a9899a86929e79525a4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0124485474315\n",
      "All Test Loss: 0.143987867459 AUC: 0.964429958138\n",
      "---Epoch 13---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cbd74f52937437c84f3cffbe0a6e04c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0117764510252\n",
      "All Test Loss: 0.143933041373 AUC: 0.96420766527\n",
      "---Epoch 14---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fc17fd23f784e79a33a9f63ab94dd83"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.245893806343\n",
      "All Test Loss: 0.142107280121 AUC: 0.964942883794\n",
      "---Epoch 15---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bf5104480ad43f2b275c2727a98def9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0331036429638\n",
      "All Test Loss: 0.142770702788 AUC: 0.965062610559\n",
      "---Epoch 16---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "533d95e180364dbeb8475f6205ccb08a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.168224077712\n",
      "All Test Loss: 0.145727886971 AUC: 0.965072583465\n",
      "---Epoch 17---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eec44cdd17c45b49c8b9ee0759659a8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0320875851985\n",
      "All Test Loss: 0.144114329143 AUC: 0.964893131709\n",
      "---Epoch 18---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aad9c77cd8e483291e5b1788ed8cc10"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.470876915236\n",
      "All Test Loss: 0.140383965737 AUC: 0.966068213326\n",
      "---Epoch 19---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76f9dec72b194df18fabd6de37aee1b4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.442898152727\n",
      "All Test Loss: 0.143962507572 AUC: 0.965835912954\n",
      "---Epoch 20---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebe3d913e86b4345bc802076d17b31ae"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.439247538176\n",
      "All Test Loss: 0.139042687665 AUC: 0.965757556881\n",
      "---Epoch 21---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b33fd22d5ada4a39bc158aa46e50573b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0306171698938\n",
      "All Test Loss: 0.139629196815 AUC: 0.96656082989\n",
      "---Epoch 22---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1279301241cf42aab33d56d4bafe41d4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.453348241695\n",
      "All Test Loss: 0.140140373961 AUC: 0.965696759349\n",
      "---Epoch 23---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49414ff6c77f42c6817333f74d4996d0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.115264795321\n",
      "All Test Loss: 0.140098124604 AUC: 0.965493677083\n",
      "---Epoch 24---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3e055e9b7b94880a9499295116974f0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0198815693058\n",
      "All Test Loss: 0.139922690354 AUC: 0.965762686051\n",
      "---Epoch 25---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6f4c45745644135be20ef3521f44448"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.544957226886\n",
      "All Test Loss: 0.138936136943 AUC: 0.966326124949\n",
      "---Epoch 26---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb3237f574824b579951917a67bb7121"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0131888164126\n",
      "All Test Loss: 0.139777371821 AUC: 0.96649046598\n",
      "---Epoch 27---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdf5668427b6461c9ddd0ee2fbed066b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0553513990081\n",
      "All Test Loss: 0.137772964323 AUC: 0.967153512842\n",
      "---Epoch 28---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a5831d21d5d480c9878aedd3b3f8adc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0471236004428\n",
      "All Test Loss: 0.138961425722 AUC: 0.966830833553\n",
      "---Epoch 29---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f087045eadac445ca5dfcc0246e3a0ab"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0150388183141\n",
      "All Test Loss: 0.139379353837 AUC: 0.966410258908\n",
      "---Epoch 30---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7d42f6358eb4e8ba438f07ec2bb9951"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.034301000832\n",
      "All Test Loss: 0.139863266184 AUC: 0.96727722704\n",
      "---Epoch 31---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a73fa737dfd047328514b591461cba09"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.41602470267\n",
      "All Test Loss: 0.137387094625 AUC: 0.966869479644\n",
      "---Epoch 32---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5b1d5c951214342a5141c2b084c843a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0459748328306\n",
      "All Test Loss: 0.138406451188 AUC: 0.967314705445\n",
      "---Epoch 33---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a46c54323a443cca2c4ef1ac2a2db02"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0647458239823\n",
      "All Test Loss: 0.138266111205 AUC: 0.966602287077\n",
      "---Epoch 34---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3381e48080eb4178a9197c59999a5b1b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.176307069079\n",
      "All Test Loss: 0.137719313689 AUC: 0.966345456644\n",
      "---Epoch 35---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e89bd57d463242878825a3361f2a949e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0128249388871\n",
      "All Test Loss: 0.143890371387 AUC: 0.966514745205\n",
      "---Epoch 36---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4dce0753939434dbfcde1720b89f27b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.159758409142\n",
      "All Test Loss: 0.137715176753 AUC: 0.966926670323\n",
      "---Epoch 37---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "504f6b6f10cc4f5882c7c5dd6480bec6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0142506633789\n",
      "All Test Loss: 0.136986634061 AUC: 0.966447252938\n",
      "---Epoch 38---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b3a6f268a7e432f814bdb62c1c801d3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0973869122201\n",
      "All Test Loss: 0.140085417311 AUC: 0.967083633306\n",
      "---Epoch 39---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c1395fe6c04495aa3125f48cb3b760c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.176344474033\n",
      "All Test Loss: 0.136560732767 AUC: 0.967390605052\n",
      "---Epoch 40---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e2143efacde4be1aaf9d3d8ceeaae5a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0121109514848\n",
      "All Test Loss: 0.139018802869 AUC: 0.9665459873\n",
      "---Epoch 41---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53c8bb16df9743438945a50fd8d73a3f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0744845238302\n",
      "All Test Loss: 0.137193989743 AUC: 0.966409099871\n",
      "---Epoch 42---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3c64ff678b24422a05630b41ad2b40a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.334501609686\n",
      "All Test Loss: 0.136626018957 AUC: 0.966580447019\n",
      "---Epoch 43---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9f33b0740554a3d8a98a0aa880c3a04"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.140259403323\n",
      "All Test Loss: 0.139924110032 AUC: 0.967390985632\n",
      "---Epoch 44---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aa8029cb61546fa8453aeea95a51c94"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.423780337383\n",
      "All Test Loss: 0.140794736566 AUC: 0.967103155291\n",
      "---Epoch 45---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b97e2e3b63c74979835087cec44d76e3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.01271108869\n",
      "All Test Loss: 0.138568907567 AUC: 0.966996480663\n",
      "---Epoch 46---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99e4dc00742c4597923795171d250b31"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0406268289811\n",
      "All Test Loss: 0.138345101038 AUC: 0.967562211686\n",
      "---Epoch 47---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c7ed4bf783f437dbdd6b066e4ce2608"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0135938390111\n",
      "All Test Loss: 0.13832479059 AUC: 0.96728896445\n",
      "---Epoch 48---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "215d00b94d794d6aba2b37004d1e84e1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0173319892253\n",
      "All Test Loss: 0.137412427318 AUC: 0.967030923083\n",
      "---Epoch 49---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8166a65fb64a4a8f807dff57710dc947"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0612885165286\n",
      "All Test Loss: 0.137122390331 AUC: 0.967358342313\n",
      "---Epoch 50---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92a1c7a858a54caabe85000cb535566e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0194290433141\n",
      "All Test Loss: 0.146653382155 AUC: 0.966951875047\n",
      "---Epoch 51---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8d62d8ba56e46c4bae5e0965c0be230"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0643155795751\n",
      "All Test Loss: 0.138523044586 AUC: 0.96718506632\n",
      "---Epoch 52---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b50fb16b56784f94ae702a2d8567cf33"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0187965774866\n",
      "All Test Loss: 0.137822748159 AUC: 0.966778633652\n",
      "---Epoch 53---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92d9b9738abe45e6b136b418fc98c55d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0105518460369\n",
      "All Test Loss: 0.137311165826 AUC: 0.967316236411\n",
      "---Epoch 54---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "571ac27b44da441cafae82df5512fc8e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.122968971771\n",
      "All Test Loss: 0.138177437643 AUC: 0.96713925842\n",
      "---Epoch 55---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "060e56fb44364b5e96f74d6bdfe85fe1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0983925235828\n",
      "All Test Loss: 0.1369502446 AUC: 0.967519690607\n",
      "---Epoch 56---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5686ff5dd650471e939e0b9a3fdfca4c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0170401313792\n",
      "All Test Loss: 0.137746413962 AUC: 0.967471979811\n",
      "---Epoch 57---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0255fab9a2340369f2b209e460b730c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.473229725084\n",
      "All Test Loss: 0.137404783949 AUC: 0.967349934972\n",
      "---Epoch 58---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37157c67788c4214aaea2e4d13b5580c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0605711003363\n",
      "All Test Loss: 0.136964501155 AUC: 0.966998617096\n",
      "---Epoch 59---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eea81f99698b488fa442bfae2be96331"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0242826851465\n",
      "All Test Loss: 0.140103602689 AUC: 0.96759017561\n",
      "---Epoch 60---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4906bbee21241ddb790258be1f9b9f5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0175708961795\n",
      "All Test Loss: 0.139123766914 AUC: 0.966939350531\n",
      "---Epoch 61---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1593c274b7d547a8995d6f9f70bb5be9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0977246425017\n",
      "All Test Loss: 0.136957307015 AUC: 0.967478034481\n",
      "---Epoch 62---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2d8a9337a3745edb808af866038a961"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.046394925127\n",
      "All Test Loss: 0.140236292795 AUC: 0.966757321216\n",
      "---Epoch 63---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1b12f81d4e94847b162d90ef6cd0dbe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0167075908689\n",
      "All Test Loss: 0.137265494882 AUC: 0.96757827386\n",
      "---Epoch 64---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a50d723f4384b9480e1f79fc96fb9fd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Model1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model1, self).__init__()\n",
    "        self.post_embedding = nn.Embedding(3182, 2)\n",
    "        self.drug_embedding = nn.Embedding(2870, 20)#changed from 30\n",
    "        #self.inp_embedding = nn.Embedding(2, 10)\n",
    "        self.dx_embedding = nn.Embedding(12, 7) #changed from 5 to 7\n",
    "        self.gru1 = nn.GRU(35, 96, 4, batch_first=True,dropout=0.2)\n",
    "        self.dense1 = nn.Linear(96, 2)\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "    \n",
    "    def forward(self, hidden, inp, posts, drugs, dxs):\n",
    "        posts_e = self.post_embedding(posts)\n",
    "        drugs_e = self.drug_embedding(drugs)\n",
    "        dxs_e = self.dx_embedding(dxs)\n",
    "        #inp_e = self.inp_embedding(inp)\n",
    "        final_input = torch.cat((hidden, inp, posts_e, drugs_e, dxs_e),dim=2)\n",
    "    \n",
    "        h_1 = Variable(torch.zeros(4,inp.size(0), 96).double(), requires_grad=False).cuda()\n",
    "        output, h_2 = self.gru1(final_input, h_1)\n",
    "\n",
    "        x = self.dense1(h_2[-1])\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "#np.random.seed(42) # new seed\n",
    "#torch.manual_seed(42)\n",
    "\n",
    "model = Model1()\n",
    "model.double()\n",
    "model.cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=0)\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "test_aucs = []\n",
    "\n",
    "train(chkpoint='model17_post9_4_96_lr_0001.tar', \n",
    "      epochs=300, \n",
    "      model=model, \n",
    "      optimizer=optimizer, \n",
    "      criterion=criterion, \n",
    "      test_losses=test_losses,\n",
    "     train_losses=train_losses,\n",
    "     test_aucs=test_aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dict = torch.load('model10_post9_3_64_lr_001/epoch-2-963.tar')\n",
    "#data_dict['optimizer'] = torch.optim.Adam(model.parameters(), lr=0.0003)\n",
    "#data_dict['optimizer'] = torch.optim.SGD(model.parameters(), lr=0.001, momentum=1.3, nesterov=True)\n",
    "train(chkpoint='model10_post9_3_64_lr_001.tar', epochs=30, **data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Epoch 19---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89ded35eeb27480a87bf52d2ddd06c3e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0882221857078\n",
      "All Test Loss: 0.137210664155 AUC: 0.966882912361\n",
      "---Epoch 20---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "178a96377f8f47b28beda478122e69bd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.187242742521\n",
      "All Test Loss: 0.141372579546 AUC: 0.965857830858\n",
      "---Epoch 21---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02d25a4108f84b07adacfed27c53c8d5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0842310044231\n",
      "All Test Loss: 0.140310185558 AUC: 0.966894770864\n",
      "---Epoch 22---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7498383608742bfb39dbe7bbd5920a4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0407696297891\n",
      "All Test Loss: 0.140559540034 AUC: 0.966555034706\n",
      "---Epoch 23---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4049ceaf9cbe4c20a23a4f8102e2c713"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0192146036612\n",
      "All Test Loss: 0.140120922814 AUC: 0.966307191133\n",
      "---Epoch 24---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2335567da1a491eb5233aef384eaca3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.374695956372\n",
      "All Test Loss: 0.13882760964 AUC: 0.966562092721\n",
      "---Epoch 25---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6ee8f22ed7d4cbd86ee0f7b46c28633"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0162339988752\n",
      "All Test Loss: 0.144060908465 AUC: 0.967039373672\n",
      "---Epoch 26---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afd3926a652946268a0a38be0954eb89"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.468255587505\n",
      "All Test Loss: 0.138188695435 AUC: 0.966005495599\n",
      "---Epoch 27---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7898119c6be42baa9b681363051ae34"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.0333150666509\n",
      "All Test Loss: 0.138592460651 AUC: 0.966949565623\n",
      "---Epoch 28---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fe0b0e679b94f958b2610d5bb6619bb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-21e6da6b624d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model15_post9_4_64_lr_0001/epoch-18-966.tar'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model15_post9_4_64_lr_0001.tar'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-ee7c04ec1599>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(chkpoint, epochs, model, criterion, optimizer, train_losses, test_losses, test_aucs, cur_epoch, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mnum_cycles\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcycle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_cycles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrugs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchify_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-35d127bec854>\u001b[0m in \u001b[0;36mrandom_batch\u001b[0;34m(batch_size)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrandom_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mchunk_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbucketlengths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbucketlengths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbucketlengths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mbucket\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pt_by_len\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchunk_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbucket\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbucket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_dict = torch.load('model15_post9_4_64_lr_0001/epoch-18-966.tar')\n",
    "train(chkpoint='model15_post9_4_64_lr_0001.tar', epochs=200, **data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.958957016353 0.00762216388464\n",
      "CPU times: user 19.3 s, sys: 565 ms, total: 19.8 s\n",
      "Wall time: 19.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "aucs = np.array([validate(model)[1] for x in range(10)])\n",
    "print np.mean(aucs), np.std(aucs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62930d9b0c4b461094280b1b24b577bc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_dict = torch.load('model11_post9_4_64_lr_001/epoch-19-965.tar')\n",
    "generate_predictions_csv(data_dict['model'], 'out-log-softmax-965.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring where the mistakes are coming from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_true = np.zeros((test_total))\n",
    "all_pred = np.zeros((test_total))\n",
    "\n",
    "bad_answers = []\n",
    "\n",
    "total_test_loss = 0\n",
    "i = 0\n",
    "for b in test_pt_by_len:\n",
    "    hidden, inp, target = prepare_input(np.array(test_pt_by_len[b]))\n",
    "    target2 = target[:]\n",
    "    hidden2 = hidden[:]\n",
    "    inp2 = inp[:]\n",
    "    hidden, inp, posts, drugs, dxs, target = torchify_batch(hidden, inp, target)\n",
    "    out = model(hidden.cuda(), inp.cuda(), posts.cuda(), drugs.cuda(), dxs.cuda())\n",
    "\n",
    "    target.cuda()\n",
    "\n",
    "    loss = criterion(out, target.cuda())\n",
    "    out_np = out.data.cpu().numpy()\n",
    "    for j in xrange(target2.shape[0]):\n",
    "        all_true[i] = int(target2[j])\n",
    "        all_pred[i] = out_np[j][1]\n",
    "        if abs(all_true[i] - all_pred[i]) > 0.99:\n",
    "            bad_answers.append((target2[j], hidden2[j], inp2[j]))\n",
    "        i += 1\n",
    "    total_test_loss += loss.data.cpu().numpy()[0]\n",
    "test_loss = total_test_loss/288\n",
    "test_auc = roc_auc_score(all_true, all_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "802\n"
     ]
    }
   ],
   "source": [
    "uros = 0\n",
    "for target, hidden, transaction in bad_answers:\n",
    "    uros += (np.sum(transaction[:, 4] == 11) > 0)\n",
    "print uros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7180.51899610243"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "802.0 / test_total * total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error = all_true - all_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc4b7289910>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc4b6efab50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(all_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc4b6e94c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc4b6b3bed0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAAD8CAYAAAC4uSVNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc4b6fbbf90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.distplot(error)\n",
    "plt.show()\n",
    "sns.distplot(np.abs(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1354\n",
      "861\n",
      "0.0313626926019\n"
     ]
    }
   ],
   "source": [
    "print np.sum(np.abs(error) > 0.01) 1354\n",
    "print np.sum(np.abs(error) > 0.99) 864\n",
    "print 861.0/test_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.abs(error) > 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27453"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6753d0390b74d0b83fd08014f1cf555"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generate_predictions_csv(model, 'out1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Epoch 8---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a46f5c5933874bc7b1af983bb6de46b4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train('model_post1.1_3_32_lr_001.tar', epochs=10, **torch.load('model_post1_3_32_lr_001.tar'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': CrossEntropyLoss (\n",
       " ), 'cur_epoch': 4, 'model': Model1 (\n",
       "   (drug_embedding): Embedding(2870, 30)\n",
       "   (dx_embedding): Embedding(12, 5)\n",
       "   (gru1): GRU(39, 32, num_layers=3, batch_first=True)\n",
       "   (dense1): Linear (32 -> 2)\n",
       "   (softmax): Softmax ()\n",
       " ), 'optimizer': <torch.optim.adam.Adam at 0x7f23016a2350>, 'test_aucs': [0.9497745120551091,\n",
       "  0.95737772101378837,\n",
       "  0.96352282510260245,\n",
       "  0.97322535701846047], 'test_losses': [0.35393751389666983,\n",
       "  0.35761409787089349,\n",
       "  0.35281944691292533,\n",
       "  0.34829183176775053], 'train_losses': [0.37126914617345386,\n",
       "  0.33828777079089706,\n",
       "  0.33836713117440947,\n",
       "  0.39558140579214862]}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load('model_3_32_lr_001.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47bc7c8a91274a079942b00ee753648a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.35821641802842302, 0.94314307203172887)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def validate_all(model):\n",
    "    all_true = np.zeros((test_total, 2))\n",
    "    all_pred = np.zeros((test_total, 2))\n",
    "    total_test_loss = 0\n",
    "    i = 0\n",
    "    for b in tqdm_notebook(test_pt_by_len):\n",
    "        hidden, inp, target = prepare_input(np.array(test_pt_by_len[b]))\n",
    "        target2 = target[:]\n",
    "        hidden, inp, posts, drugs, dxs, target = torchify_batch(hidden, inp, target)\n",
    "        out = model(hidden.cuda(), inp.cuda(), posts.cuda(), drugs.cuda(), dxs.cuda())\n",
    "\n",
    "        target.cuda()\n",
    "\n",
    "        loss = criterion(out, target.cuda())\n",
    "        out_np = out.data.cpu().numpy()\n",
    "        for j in xrange(target2.shape[0]):\n",
    "            all_true[i, int(target2[j])] = 1\n",
    "            all_pred[i] = out_np[j]\n",
    "            i += 1\n",
    "        total_test_loss += loss.data.cpu().numpy()[0]\n",
    "    test_loss = total_test_loss/288\n",
    "    test_auc = roc_auc_score(all_true, all_pred)\n",
    "    return test_loss, test_auc\n",
    "\n",
    "validate_all(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27453"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
